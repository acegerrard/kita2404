{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Function Calling의 사용\n",
        "- 이 코드에서 function calling은 모델이 적절한 시점에 외부 함수(get_current_weather)를 호출하도록 유도합니다. 모델이 What is the current weather in {user_location}?와 같은 질문에 응답할 때, 해당 함수가 정의되어 있으면 모델은 그 함수를 호출하여 날씨 정보를 가져오려 합니다.\n",
        "\n",
        "- function_call=\"auto\" 설정을 통해 GPT 모델은 적절한 함수가 있을 때 자동으로 그 함수를 호출할 수 있습니다. 여기서는 get_current_weather 함수 명세를 통해 사용자가 입력한 위치에 맞는 날씨 정보를 가져올 수 있도록 유도됩니다.\n",
        "\n",
        "- 만약 모델이 함수 호출을 결정하면, 응답에 function_call이 포함되며, 이때 함수 이름과 그 인자가 함께 반환됩니다. 그런 후에 함수가 호출되고, 결과가 다시 모델에 제공됩니다.\n",
        "\n",
        "이 과정에서 모델은 단순히 인자를 생성하고, 함수를 호출하는 것은 개발자의 책임입니다. OpenAI의 API는 실제 함수 실행을 수행하지 않으므로, 함수 호출 후 결과를 처리하고 다시 모델에 넘기는 과정을 수동으로 처리하게 됩니다."
      ],
      "metadata": {
        "id": "Zf2Dkd76Aszt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBuDtWnd_yRh",
        "outputId": "b960fb3e-fc65-46bd-d656-9e37f75e1ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m358.4/362.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://home.openweathermap.org/"
      ],
      "metadata": {
        "id": "xJHTuqJvCQjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='')\n",
        "\n",
        "# 날씨 API 키 설정\n",
        "weather_api_key = '2e1e37fd42dd84270c25d13cbba0c19f'\n",
        "\n",
        "# 날씨 정보를 가져오는 함수 정의\n",
        "def get_current_weather(location):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={weather_api_key}&units=metric\"\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# 사용자 요청 메시지\n",
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "    {'role': 'user', 'content': 'What is the current weather in New York?'}\n",
        "]\n",
        "\n",
        "# GPT-4 모델 호출\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini',\n",
        "    messages = messages,\n",
        "    functions = [{\n",
        "        'name': 'get_current_weather',\n",
        "        'description': 'Get the current weather for a specific location',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'location': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'The name of the city to get the weather for',\n",
        "                },\n",
        "            },\n",
        "            'required': ['location'],\n",
        "        },\n",
        "    }],\n",
        "    function_call = 'auto'\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "\n",
        "print(response_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXqVNtHKCG8n",
        "outputId": "9c767f0c-6164-4363-bae9-b5eb9be1286a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"New York\"}', name='get_current_weather'), tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 도구 호출 여부 확인\n",
        "\n",
        "function_call = response_message.function_call\n",
        "if function_call:\n",
        "    tool_function_name = function_call.name\n",
        "    tool_arguments = json.loads(function_call.arguments)\n",
        "\n",
        "    # 함수 호출 및 결과 처리\n",
        "    if tool_function_name == 'get_current_weather':\n",
        "        location = tool_arguments['location']\n",
        "        weather_results = get_current_weather(location)\n",
        "\n",
        "        # 함수 호출 결과 메시지 추가\n",
        "\n",
        "        messages.append({\n",
        "            'role': 'function',\n",
        "            'name': tool_function_name,\n",
        "            'content': json.dumps(weather_results) # json형식으로 반환\n",
        "        })\n",
        "        # print(messages)\n",
        "        # 모델 재호출\n",
        "        model_response_with_function_call = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini',\n",
        "            messages = messages\n",
        "        )\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "    else:\n",
        "        print(f'Error: function {tool_function_name} does not exist')\n",
        "else:\n",
        "    # 도구 호출이 없는 경우 결과 반환\n",
        "    print(response_message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvOYfeZHHCJN",
        "outputId": "3d830075-4147-4aad-9ec3-efcade04d1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in New York is as follows:\n",
            "\n",
            "- **Temperature**: 21.7°C (feels like 22.3°C)\n",
            "- **Condition**: Mist\n",
            "- **Humidity**: 92%\n",
            "- **Visibility**: Approximately 4.8 km\n",
            "- **Wind**: From the northeast at 4.6 m/s (gusts up to 7.7 m/s)\n",
            "- **Cloud Cover**: 100%\n",
            "\n",
            "Overall, it seems to be a misty day in New York.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='')\n",
        "\n",
        "# 날씨 API 키 설정\n",
        "weather_api_key = '2e1e37fd42dd84270c25d13cbba0c19f'\n",
        "\n",
        "# 날씨 정보를 가져오는 함수 정의\n",
        "def get_current_weather(location):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={weather_api_key}&units=metric\"\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# 사용자 요청 메시지 초기화\n",
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "    {'role': 'user', 'content': 'plese provide the location to get the current weather infomation'}\n",
        "]\n",
        "\n",
        "# 사용자 입력 받기\n",
        "user_location = input('Enter the location: ')\n",
        "messages.append({'role': 'user', 'content': f'What is the current weather in {user_location}?'})\n",
        "\n",
        "# GPT-4 모델 호출\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini',\n",
        "    messages = messages,\n",
        "    functions = [{\n",
        "        'name': 'get_current_weather',\n",
        "        'description': 'Get the current weather for a specific location',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'location': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'The name of the city to get the weather for',\n",
        "                },\n",
        "            },\n",
        "            'required': ['location'],\n",
        "        },\n",
        "    }],\n",
        "    function_call = 'auto'\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "\n",
        "print(response_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aWlinAfSMib",
        "outputId": "6b4517a4-24f5-46a3-db9c-019f0eb82dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the location: seoul\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"Seoul\"}', name='get_current_weather'), tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 도구 호출 여부 확인\n",
        "\n",
        "function_call = response_message.function_call\n",
        "if function_call:\n",
        "    tool_function_name = function_call.name\n",
        "    tool_arguments = json.loads(function_call.arguments)\n",
        "\n",
        "    # 함수 호출 및 결과 처리\n",
        "    if tool_function_name == 'get_current_weather':\n",
        "        location = tool_arguments['location']\n",
        "        weather_results = get_current_weather(location)\n",
        "\n",
        "        # 함수 호출 결과 메시지 추가\n",
        "\n",
        "        messages.append({\n",
        "            'role': 'function',\n",
        "            'name': tool_function_name,\n",
        "            'content': json.dumps(weather_results) # json형식으로 반환\n",
        "        })\n",
        "        # print(messages)\n",
        "        # 모델 재호출\n",
        "        model_response_with_function_call = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini',\n",
        "            messages = messages\n",
        "        )\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "    else:\n",
        "        print(f'Error: function {tool_function_name} does not exist')\n",
        "else:\n",
        "    # 도구 호출이 없는 경우 결과 반환\n",
        "    print(response_message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieoBK3aSSyLv",
        "outputId": "60535822-9a9e-48a1-d891-ab926df4f5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in London is as follows:\n",
            "\n",
            "- **Condition**: Scattered clouds\n",
            "- **Temperature**: 14.25°C\n",
            "- **Feels Like**: 13.77°C\n",
            "- **Humidity**: 78%\n",
            "- **Wind Speed**: 0.69 m/s from the west (286°)\n",
            "- **Cloud Cover**: 40%\n",
            "\n",
            "The temperature can vary, with a minimum of 11.62°C and a maximum of 16.12°C expected.\n",
            "\n",
            "If you need more detailed weather information or forecasts, websites like [Weather.com](https://www.weather.com/) or [BBC Weather](https://www.bbc.co.uk/weather) can provide extensive details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to call functions with model generated arguments\n",
        "\n",
        "다음 예제에서는 모델에서 생성된 입력을 갖는 함수를 실행하는 방법을 보여주고 이를 사용하여 데이터베이스에 대한 질문에 답할 수 있는 에이전트를 구현합니다. 단순화를 위해 Chinook 샘플 데이터베이스를 사용하겠습니다 .\n",
        "\n",
        "참고: 모델이 올바른 SQL을 생성하는 데 완벽하게 신뢰할 수 없기 때문에 프로덕션 환경에서 SQL 생성은 위험할 수 있습니다.\n",
        "\n",
        "이 코드는 OpenAI의 GPT 모델을 사용하여 SQLite 데이터베이스에서 음악 관련 질문에 대한 답변을 SQL 쿼리로 변환한 후, 해당 쿼리를 실행하여 결과를 반환하는 방식으로 function calling을 구현한 예시입니다. 여기서는 사용자가 앨범 관련 질문을 하면, GPT-4가 질문을 SQL 쿼리로 변환하고, SQLite 데이터베이스를 조회하여 결과를 반환합니다."
      ],
      "metadata": {
        "id": "flm84kQ3YIYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "specifying a function to execute sql queries\n",
        "\n",
        "먼저 sqlite 데이터베이스에서 데이터를 추출하는데 유용한 유틸리티 함수를 정의\n",
        "chinook.db 데이터베이스에 연결하여 sqlite를 통해 sql쿼리를 실행"
      ],
      "metadata": {
        "id": "8Tl6TV33ZMk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# sqlite3.connect()를 통해 google drive에 있는 chinook.db sqlite 데이터베이스에 연결\n",
        "conn = sqlite3.connect('/content/drive/MyDrive/kdt_240424/M9_LLM/dataset/Chinook.db')\n",
        "print(\"Opened database successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVtlfwS1YJdl",
        "outputId": "31ed5503-182e-4c6a-bf71-d8dbbcfb8ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Opened database successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터베이스 테이블 및 열 정보 조회\n",
        "\n",
        "- get_table_names, get_column_names 함수를 통해 데이터베이스의 테이블 및 열 이름을 가져옵니다.\n",
        "- 이 정보는 나중에 GPT 모델이 SQL 쿼리를 생성할 때 사용할 스키마 정보를 제공하는 데 활용됩니다."
      ],
      "metadata": {
        "id": "QQ_1-9NPZf7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 베이스에서 테이블 목록을 추출하는 함수 sqlite_master 테이블에서 type이 table인 항목들의 이름을 가져와 리스트로 반환\n",
        "\n",
        "def get_table_names(conn):\n",
        "    \"\"\"Return a list of table names.\"\"\"\n",
        "    table_names = []\n",
        "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    for table in tables.fetchall():\n",
        "        table_names.append(table[0])\n",
        "    return table_names\n",
        "\n",
        "# PRAGMA table_info(table_name) 명령을 사용하여 테이블의 스키마 정보를 가져오고 컬럼 이름을 리스트로 반환\n",
        "def get_column_names(conn, table_name):\n",
        "    \"\"\"Return a list of column names.\"\"\"\n",
        "    column_names = []\n",
        "    columns = conn.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
        "    for col in columns:\n",
        "        column_names.append(col[1])\n",
        "    return column_names\n",
        "\n",
        "def get_database_info(conn):\n",
        "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
        "    table_dicts = []\n",
        "    for table_name in get_table_names(conn):\n",
        "        columns_names = get_column_names(conn, table_name)\n",
        "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
        "    return table_dicts\n"
      ],
      "metadata": {
        "id": "m4pNncuPZ2mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터베이스의 테이블과 열 정보를 문자열 형태로 저장하여, 나중에 SQL 쿼리 작성시 참수 할 수 있도록 합니다"
      ],
      "metadata": {
        "id": "1jwG1WKKcSXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "database_schema_dict = get_database_info(conn)\n",
        "database_schema_string = '\\n'.join(\n",
        "    [\n",
        "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
        "        for table in database_schema_dict\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "-O_UA2nDcal8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            'name': 'ask_database',\n",
        "            'description': 'Use this function to answer user questions about music. Output should be a fully formed SQL query.',\n",
        "            'parameters': {\n",
        "                'type': 'object',\n",
        "                'properties': {\n",
        "                    'query': {\n",
        "                        'type': 'string',\n",
        "                        'description': f\"\"\"\n",
        "                                SQL query extracting info to answer the user's question.\n",
        "                                SQL should be written using this database schema:\n",
        "                                {database_schema_string}\n",
        "                                The query should be returned in plain text, not in JSON.\n",
        "                                \"\"\",\n",
        "                    }\n",
        "                },\n",
        "                'required': ['query']\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "yYPJNWXPeRZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing SQL queries\n",
        "\n",
        "이는 실제로 데이터베이스에 대한 쿼리를 실행하는 함수를 구현"
      ],
      "metadata": {
        "id": "wxa6z94DfYtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_database(conn, query):\n",
        "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
        "    try:\n",
        "        results = str(conn.execute(query).fetchall())\n",
        "    except Exception as e:\n",
        "        results = f\"query failed with error: {e}\"\n",
        "    return results"
      ],
      "metadata": {
        "id": "k7Ip0BecfiAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3pxqchTOgrlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자의 요청 메시지를 정의\n",
        "\n",
        "messages = [{\n",
        "    'role': 'user',\n",
        "    'content': 'what is the name of the album with the most tracks'\n",
        "}]\n",
        "\n",
        "# 사용자의 질문에 대한 응답을 생성. tools 와 tool_choice 파라미터는 모델이 데이터베이스 쿼리를 인식하고 자동으로 도구를 선택할 수 있도록 도움\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini',\n",
        "    messages = messages,\n",
        "    tools = tools,\n",
        "    tool_choice = 'auto' # 모델이 자동으로 함수 호출을 결정, SQL 쿼리로 변화할 필요가 있다고 판단하면 자동으로 ask_database 함수를 호출\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "print(response_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyiFbGw6hCiS",
        "outputId": "b4a1bf2f-8a25-424e-d0c0-d5ac94e12b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_oDeLHJW4oT4nJ9zf5wtkey2c', function=Function(arguments='{\"query\":\"SELECT Album.Title FROM Album JOIN (SELECT AlbumId, COUNT(*) AS TrackCount FROM Track GROUP BY AlbumId ORDER BY TrackCount DESC LIMIT 1) AS MostTracks ON Album.AlbumId = MostTracks.AlbumId;\"}', name='ask_database'), type='function')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 응답에서 도구 호출이 포함되어 있는지 확인하고 도구 호출이 있다면 도구 호출 ID 함수 이름 및 쿼리 문자열을 추출\n",
        "\n",
        "tool_calls = response_message.tool_calls\n",
        "if tool_calls:\n",
        "    # if true the model will return the name of the tool / function to call the argument(s)\n",
        "    tool_call_id = tool_calls[0].id\n",
        "    tool_function_name = tool_calls[0].function.name\n",
        "    tool_function_string = json.loads(tool_calls[0].function.arguments)['query']\n",
        "\n",
        "    # 도구 호출 함수 이름이 'ask_database'인 경우 , ask_database 함수를 호출하여 데이터베이스 쿼리를 실행하고 결과를 messages 리스트에 추가\n",
        "    if tool_function_name == 'ask_database':\n",
        "        results = ask_database(conn, tool_function_string)\n",
        "\n",
        "        messages.append({\n",
        "            'role': 'tool',\n",
        "            'tool_call_id': tool_call_id,\n",
        "            'name': tool_function_name,\n",
        "            'content': results\n",
        "        })\n",
        "\n",
        "        # 도구 호출 결과가 포함된 messages 리스트를 사용하여 모델을 다시 호출하고 최종 응답을 출력\n",
        "        # Note that messages with role 'tool' must be a response to a preceding message with 'tool_call'\n",
        "        model_response_with_function_call = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini',\n",
        "            messages = messages\n",
        "        )  # get a new response from the model where it can see the function response\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "        # 도구 호출 함수 이름이 ask_database 가 아닌 경우 오류 메시지를 출력하거나 도구 호출이 없으면 모델의 응답 내용을 바로 출력\n",
        "    else:\n",
        "        print(f'Error: function {tool_function_name} does not exist')\n",
        "else:\n",
        "    # Model did not identify a function to call, result can be returned to the user\n",
        "    print(response_message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULGdXiGMjYqK",
        "outputId": "225deca0-a108-4df3-9951-3aa775acd122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The album with the most tracks is titled \"Greatest Hits.\"\n"
          ]
        }
      ]
    }
  ]
}