{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.gradio.app/guides"
      ],
      "metadata": {
        "id": "CQg5tD9XqqR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio는 Python 기반의 라이브러리로, 머신러닝 모델 또는 일반적인 함수와 사용자 간의 상호작용을 위한 웹 인터페이스를 간단하게 구축할 수 있도록 도와줍니다. Gradio를 사용하면 몇 줄의 코드로 웹 애플리케이션을 만들 수 있으며, 이를 통해 모델이나 함수를 사용자에게 쉽게 배포할 수 있습니다.\n",
        "\n",
        "**Gradio의 기본 개념**\n",
        "\n",
        "- 웹 인터페이스: Gradio는 머신러닝 모델 또는 일반적인 파이썬 함수를 웹 브라우저에서 실행할 수 있도록 UI를 제공합니다. 이를 통해 사용자는 모델을 직접 입력값을 주거나 결과를 확인할 수 있습니다.\n",
        "- 사용자 상호작용: Gradio는 텍스트 입력, 파일 업로드, 드롭다운 메뉴 등 다양한 위젯을 제공하여 사용자가 쉽게 상호작용할 수 있는 환경을 제공합니다.\n",
        "- 빠른 프로토타이핑: 복잡한 웹 서버 설정 없이도 간단하게 모델을 웹에서 테스트하고 배포할 수 있습니다.\n",
        "\n",
        "**Gradio의 핵심 기능**\n",
        "- 인터페이스 구성 요소:\n",
        "Gradio는 다양한 입력 및 출력 위젯을 제공합니다. 이를 사용하여 웹 기반 인터페이스를 만들 수 있습니다.\n",
        "  - 입력 위젯: Textbox, Dropdown, Slider, Checkbox, FileUpload 등\n",
        "  - 출력 위젯: Textbox, Label, Image, Audio, Video 등\n",
        "- Interface: Gradio의 기본 클래스입니다. 함수를 UI 위젯과 연결하여 웹 애플리케이션을 쉽게 만들 수 있습니다.\n",
        "  - fn: 실행할 함수\n",
        "  - inputs: 사용자 입력을 받는 위젯\n",
        "  - outputs: 함수의 결과를 표시하는 위젯\n",
        "  \n",
        "- Blocks: 복잡한 레이아웃을 만들거나 여러 위젯을 연결할 때 사용되는 블록 구조입니다. Blocks는 여러 컴포넌트를 모듈식으로 구성할 수 있으며, 복잡한 인터페이스를 구성할 때 유용합니다.\n",
        "\n",
        "- 상태 관리 (gr.State): 여러 함수 호출 간에 데이터를 저장하고 공유할 수 있는 기능입니다. 대화형 애플리케이션에서 상태를 유지하거나 이전 입력값을 저장할 때 사용됩니다.\n",
        "\n",
        "- 실시간 인터페이스: Gradio는 실시간으로 사용자 입력을 처리하고, 빠르게 결과를 반환할 수 있는 기능을 제공합니다. 이를 통해 데이터 분석, 이미지 생성, 챗봇 등 다양한 실시간 애플리케이션을 구축할 수 있습니다.\n",
        "\n",
        "- 파일 업로드 및 다운로드: Gradio는 파일을 업로드하거나 다운로드하는 기능을 제공하여 사용자와의 상호작용을 더욱 다양화할 수 있습니다.\n",
        "\n",
        "- Markdown 지원: Gradio는 gr.Markdown()을 통해 인터페이스에서 간단한 텍스트 설명을 Markdown 형식으로 추가할 수 있습니다."
      ],
      "metadata": {
        "id": "rbsYqG-ErQbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSIpGOemqcx_",
        "outputId": "0170759a-0afd-43c6-caa4-d01b0c56e753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return 'Hello ' + name + '!'\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs='text', outputs='text')\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "XRtLo1WZwhoC",
        "outputId": "a0ca3cec-87a1-4d1a-b762-7a531dcfde9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ed9d1738b5cb4c70e8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ed9d1738b5cb4c70e8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return 'Hello ' + name + '!'\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox(lines=2, placeholder='Name Here...'),\n",
        "    outputs='text'\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "76RcHF24yGxZ",
        "outputId": "fdb93564-da49-4b0c-daf6-dec60199977c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://95fd7663ed9edbca51.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://95fd7663ed9edbca51.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name, is_morning, temperature):\n",
        "    salutation = 'Good morning' if is_morning else 'Good evening'\n",
        "    greeting = f'{salutation} {name}. It is {temperature} degrees today'\n",
        "    celsius = (temperature - 32) * 5/9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=['text', 'checkbox', gr.Slider(0, 100)],\n",
        "    outputs=['text', 'number']\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "Sd_72Os-y2cs",
        "outputId": "65c30da1-76dc-411d-9754-8ef5dd41f8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://301fa085cc626e65eb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://301fa085cc626e65eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "from skimage.transform import resize\n",
        "\n",
        "def sepia(input_img):\n",
        "    input_img = resize(input_img, (200, 200)) # 여기서 이미지 크기 조정\n",
        "    sepia_filter = np.array([\n",
        "        [0.393, 0.769, 0.189],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max() # 정규화\n",
        "    return sepia_img\n",
        "\n",
        "# 인터페이스 정의시 shape 매개변수 제거\n",
        "demo = gr.Interface(fn=sepia, inputs=gr.Image(), outputs=gr.Image())\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "niw4tv_h0iBl",
        "outputId": "357d92ea-27b7-4645-b6c3-5b6417234849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://968f4281a6884f2893.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://968f4281a6884f2893.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def bmi(name, height, weight, feeling):\n",
        "    bmi_val = round(weight / (height/100)**2, 2)\n",
        "    result_emoticon = '😀' if bmi_val < 30 else '😱'\n",
        "    output_str = 'Hello' + name + '...\\n your BMI is ...' + str(bmi_val)\n",
        "    txt = 'Happy' if feeling else 'Sad'\n",
        "    return (output_str, result_emoticon, txt)\n",
        "\n",
        "bmi('kangmin', 178, 67, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCOEplkU1egn",
        "outputId": "7c7c7956-dcd8-44a0-f5a0-bdb44622eea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Hellokangmin...\\n your BMI is ...21.15', '😀', 'Happy')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=bmi,\n",
        "    inputs=['text', gr.Slider(1, 200, label='Height in cm'), gr.Slider(1, 200, label='Weight in kg'),\n",
        "            gr.Checkbox(label='Your Feeling Today')],\n",
        "    outputs=['text', 'text', 'text'],\n",
        "    examples = [['kangmin', 178, 67, True],\n",
        "                ['James', 169,60, False],\n",
        "                ['kevin', 189, 70, True]],\n",
        "    live = True, # submit 없이 자동으로 제출\n",
        "    description = 'Flag if you find an erroneous output'\n",
        ")\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "4zCBFUG04nl5",
        "outputId": "cc717896-fbaf-4e55-bbd5-eb7bd1269d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://71386211f871bb241d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://71386211f871bb241d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blocks\n",
        "- Gradio의 저수준 API로 인터페이스보다 더 많은 사용자 지정 웹 응용 프로그램 및 데모를 만들 수 있습니다(아직 완전히 Python으로).\n",
        "- 인터페이스 클래스에 비해 Blocks는 다음에 대해 더 많은 유연성과 제어 기능을 제공합니다.\n",
        "- Blocks는 또한 탭과 같은 관련 데모를 함께 그룹화하는 방법을 제공합니다.\n",
        "- Blocks 객체를 생성한 다음 컨텍스트로 사용하고(\"with\" 문 사용) Blocks 컨텍스트 내에서 레이아웃, 구성 요소 또는 이벤트를 정의합니다. 마지막으로 launch() 메서드를 호출하여 데모를 시작합니다."
      ],
      "metadata": {
        "id": "mEqTSohU-IIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    text_input = gr.Textbox(label='Enter your text')\n",
        "    output = gr.Textbox(label = 'Output')\n",
        "    btn = gr.Button('submit')\n",
        "\n",
        "    btn.click(fn=greet, inputs=text_input, outputs=output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "7FoP19VS-E9d",
        "outputId": "68c51590-48d1-4187-df42-cb7c8b90d0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9e67f7a906d031bee4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9e67f7a906d031bee4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실습\n",
        "코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇\n",
        "\n",
        "- chat_with_tutor 함수: 이 함수는 OpenAI API를 호출하여 학생의 입력에 대한 튜터의 응답을 처리합니다. 이전 대화 내용을 저장하고 이어서 진행합니다.\n",
        "- start_chat 함수: '학습 시작' 버튼을 누르면 튜터의 인사말과 함께 대화가 시작됩니다.\n",
        "- Gradio UI:\n",
        "  - start_button: 학습을 시작하는 버튼입니다. 누르면 튜터의 인사말이 나타납니다.\n",
        "  - tutor_response: 튜터의 대답을 표시하는 텍스트박스입니다.\n",
        "  - user_input: 학생이 질문을 입력할 수 있는 텍스트박스입니다.\n",
        "  - submit_button: 학생이 질문을 제출하는 버튼입니다.\n",
        "  - gr.State(): 대화 기록을 유지하기 위해 사용됩니다."
      ],
      "metadata": {
        "id": "Q0kbz-C5BEtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기본 모델 - 퓨샷"
      ],
      "metadata": {
        "id": "E8x689npA7k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAVqV81UBORD",
        "outputId": "84188872-4f93-4ba2-e7e9-c5b364a3b4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='')\n",
        "\n",
        "system_msg=\"\"\"코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇입니다.\n",
        "              - 튜터는 \"반가워요\"라고 인사말로 학습을 시작합니다.\n",
        "              - 학생이 선택한 섹션으로 학습을 시작하고 먼저 간단하게 섹션 학습내용 요약을 제공합니다.\n",
        "              - 각 섹션별 학습 항목에 대해서 하나씩 개념을 명확하고 친절하게 설명하고 연습문제를 추가로 제공해서 각 개념을 이해하여 활용할 수 있도록 연습 기회를 제공합니다.\n",
        "              - 학생의 답변에 대해서 \"잘했어요!\",\"조금 더 생각해봐요~\" 와 같은 긍정적인 피드백을 제공합니다.\n",
        "              - 대화는 간결하게 유지하며, 최대 100자 이내로 진행합니다.단 코드는 300자 이내로 작성합니다.\n",
        "              - 튜터는 학생들이 자기주도 학습을 할 수 있도록 개인화 된 학습을 제공하고 모든 질의 응답을 한국어로 진행합니다.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini-2024-07-18\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system_msg},\n",
        "    {\"role\": \"user\", \"content\": \"안녕하세요. 파이썬 기초에 대하여 학습을 지도해줘요\"},\n",
        "    {\"role\": \"user\", \"content\": \"반가워요. 파이썬 기초를 학습해보도록 할게요. 먼저 파이썬의 기본 문법과 개념들을 간단히 요약해드릴게요\"},\n",
        "    {\"role\": \"system\", \"content\": '변수와 자료형에 대해 학습해줘요.'}\n",
        "  ],\n",
        "  temperature=0.7,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        ")\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "AqrTvLaZ_8q9",
        "outputId": "22178aa2-643f-4741-aea4-a4d25687e1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'변수는 데이터를 저장하는 공간입니다. 파이썬에서는 변수에 값을 할당할 수 있고, 자료형에 따라 다르게 동작합니다. 주요 자료형은 정수(int), 실수(float), 문자열(str), 불리언(bool) 등이 있어요. \\n\\n연습문제: \\n1. 변수 `a`에 10을, 변수 `b`에 3.14를 저장해보세요.\\n2. 변수 `name`에 자신의 이름을 저장해보세요. \\n\\n해보시겠어요?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Wep UI\n",
        "- chat_with_tutor 함수: 이 함수는 OpenAI API를 호출하여 학생의 입력에 대한 튜터의 응답을 처리합니다. 이전 대화 내용을 저장하고 이어서 진행합니다.\n",
        "- start_chat 함수: '학습 시작' 버튼을 누르면 튜터의 인사말과 함께 대화가 시작됩니다.\n",
        "- Gradio UI:\n",
        "  - start_button: 학습을 시작하는 버튼입니다. 누르면 튜터의 인사말이 나타납니다.\n",
        "  - tutor_response: 튜터의 대답을 표시하는 텍스트박스입니다.\n",
        "  - user_input: 학생이 질문을 입력할 수 있는 텍스트박스입니다.\n",
        "  - submit_button: 학생이 질문을 제출하는 버튼입니다.\n",
        "  - gr.State(): 대화 기록을 유지하기 위해 사용됩니다."
      ],
      "metadata": {
        "id": "jvQTA1zABJn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "# openai API 설정\n",
        "client = OpenAI(api_key='')\n",
        "\n",
        "# 시스템 메시지 설정\n",
        "system_msg=\"\"\"코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇입니다.\n",
        "              - 튜터는 \"반가워요\"라고 인사말로 학습을 시작합니다.\n",
        "              - 학생이 선택한 섹션으로 학습을 시작하고 먼저 간단하게 섹션 학습내용 요약을 제공합니다.\n",
        "              - 각 섹션별 학습 항목에 대해서 하나씩 개념을 명확하고 친절하게 설명하고 연습문제를 추가로 제공해서 각 개념을 이해하여 활용할 수 있도록 연습 기회를 제공합니다.\n",
        "              - 학생의 답변에 대해서 \"잘했어요!\",\"조금 더 생각해봐요~\" 와 같은 긍정적인 피드백을 제공합니다.\n",
        "              - 대화는 간결하게 유지하며, 최대 100자 이내로 진행합니다.단 코드는 300자 이내로 작성합니다.\n",
        "              - 튜터는 학생들이 자기주도 학습을 할 수 있도록 개인화 된 학습을 제공하고 모든 질의 응답을 한국어로 진행합니다.\"\"\"\n",
        "# 채팅 함수\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [{'role': 'system', 'content': system_msg}] + chat_history\n",
        "\n",
        "    if not chat_history: # 첫 대화일 경우 인사말과 함께 시작\n",
        "        messages.append({'role': 'user', 'content': '안녕하세요. 파이썬 기초에 대하여 학습을 지도해줘요'})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini-2024-07-18\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            max_tokens=300,\n",
        "            top_p=1,\n",
        "        )\n",
        "\n",
        "        response_msg = response.choices[0].message.content\n",
        "        chat_history.append({'role': 'assistant', 'content': response_msg})\n",
        "\n",
        "        return response_msg, chat_history\n",
        "\n",
        "# Gradio UI 구성\n",
        "def start_chat():\n",
        "    return '반가워요. 파이썬 기초를 학습해 보도록 할게요. 먼저 파이썬의 기본 문법과 개념들을 간단히 요약해 드릴게요.',[]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown('# 파이썬 튜터 봇')\n",
        "\n",
        "    chat_history = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        start_button = gr.Button('학습 시작')\n",
        "\n",
        "    tutor_response = gr.Textbox(label='튜터의 대답')\n",
        "    user_input = gr.Textbox(label='학생의 질문')\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_button = gr.Button('질문 제출')\n",
        "\n",
        "    start_button.click(start_chat, inputs=[], outputs=[tutor_response, chat_history])\n",
        "    submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history])\n",
        "\n",
        "# 실행\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "VkmmVskwD8B0",
        "outputId": "f500f328-f24d-44c6-8905-f2d693f559b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1b7465ab31008b43bb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1b7465ab31008b43bb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 536, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 321, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1945, in process_api\n",
            "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1717, in postprocess_data\n",
            "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1691, in validate_outputs\n",
            "    raise ValueError(\n",
            "ValueError: An event handler (chat_with_tutor) didn't receive enough output values (needed: 2, received: 1).\n",
            "Wanted outputs:\n",
            "    [<gradio.components.textbox.Textbox object at 0x7cdca6a24b20>, <gradio.components.state.State object at 0x7cdca6a9ec80>]\n",
            "Received outputs:\n",
            "    [None]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7870 <> https://1b7465ab31008b43bb.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}