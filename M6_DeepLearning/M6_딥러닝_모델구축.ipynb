{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn6_TlrbCZbm"
      },
      "source": [
        "## TensorFlow, Keras\n",
        "딥러닝 모델을 개발, 훈련, 평가, 배포하는 데 필요한 도구와 라이브러리를 제공하며 딥러닝을 효율적이고 쉽게 구현할 수 있도록 다양한 기능을 갖추고 있는 딥러닝 프레임워크이다.\n",
        "\n",
        "- TensorFlow: 딥러닝 모델을 정의하고 구축할 수 있는 다양한 API를 제공합니다. 고수준 API(tf.keras)와 저수준 API를 통해 다양한 모델을 유연하게 설계할 수 있습니다.\n",
        "- Keras: TensorFlow 위에서 작동하는 고수준 API로, 사용자가 간단하고 직관적으로 모델을 정의할 수 있게 도와줍니다. 직관적인 레이어 기반의 접근 방식을 사용해 빠르게 모델을 구축할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLT88kstCfQn"
      },
      "source": [
        "텐서플로우(TensorFlow)의 케라스(Keras)\n",
        "\n",
        "- 머신러닝(딥러닝도 포함) 모델을 쉽고 빠르게 개발할 수 있도록 도와주는 고수준의 신경망 API. 원래 케라스는 독립적인 딥러닝 라이브러리로 시작되었지만, 텐서플로우 1.0 버전부터는 텐서플로우의 공식 프론트엔드로 통합되었고, 텐서플로우 2.0 이후부터는 텐서플로우의 기본 API로 자리잡았다.\n",
        "- 케라스는 사용자 친화적이며 모듈식으로 구성되어 있어, 신경망의 레이어(layer), 활성화 함수(activation function), 손실 함수(loss function) 등을 마치 레고 블록을 조립하듯 쉽게 조합하여 모델을 구성할 수 있다. 이를 통해 컴퓨터 비전, 자연어 처리와 같은 다양한 머신러닝 애플리케이션을 신속하게 개발할 수 있다.\n",
        "\n",
        "주요 특징\n",
        "\n",
        "- 사용자 친화성: 케라스는 일관된 API를 제공하며, 일반적인 사용 사례에 대한 간결한 코드를 지향합니다. 이를 통해 사용자가 직관적으로 이해하고 사용할 수 있다.\n",
        "- 모듈성: 모델은 독립적인 모듈, 즉 레이어, 손실 함수, 활성화 함수, 최적화 알고리즘 등의 조합으로 구성됩니다. 이러한 모듈은 최소한의 제약으로 서로 연결될 수 있어, 매우 유연한 모델 설계가 가능.\n",
        "- 확장성: 케라스는 새로운 레이어나 기타 모듈을 만들어 추가하는 것이 상대적으로 쉽습니다. 따라서 연구 목적으로 새로운 아이디어를 실험하고자 할 때 매우 유용.\n",
        "- 파이썬 기반: 케라스는 순수 파이썬으로 작성되어 있으며, 딥러닝 모델을 파이썬 코드로 쉽게 작성할 수 있다.\n",
        "\n",
        "기본 구성 요소\n",
        "- 모델: Sequential 모델과 함수형 API를 통해 신경망을 구성할 수 있다. - Sequential 모델은 레이어를 순차적으로 쌓는 간단한 방식이며, 함수형 API는 더 복잡한 모델을 구성할 수 있는 유연성을 제공.\n",
        "- 레이어: 다양한 유형의 레이어(예: Dense(완전 연결 레이어), Conv2D(2D 컨볼루션 레이어), RNN(재귀 신경망 레이어))를 제공.\n",
        "- 손실 함수: 모델의 예측과 실제 값 사이의 차이를 측정하는 함수입니다. 예를 들어, 회귀 문제에는 mean_squared_error, 분류 문제에는 categorical_crossentropy가 자주 사용.\n",
        "- 옵티마이저: 경사하강법 알고리즘을 구현한 것으로, adam, sgd, rmsprop 등이 있다. 모델의 손실을 최소화하기 위해 모델 파라미터를 업데이트하는 방법을 정의.\n",
        "- 평가 지표: 학습과 테스트 단계에서 모델의 성능을 평가하기 위해 사용되는 지표들이다. 예를 들어, 정확도(accuracy), 정밀도(precision), 재현율(recall) 등이 있다.\n",
        "\n",
        "케라스는 이러한 구성 요소들을 사용하여 다양한 신경망 아키텍처를 구현하고, 이를 텐서플로우 백엔드를 통해 효율적으로 실행할 수 있게 해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_J5N6tCnAE"
      },
      "source": [
        "### 텐서플로우(TensorFlow) 모델 구축 방법\n",
        "Sequential API와 함수형(Functional) API. 이 두 방법은 신경망 모델을 정의, 구축 및 실험하는 데 사용되며, 사용자의 필요와 모델의 복잡성에 따라 적합한 방법을 선택할 수 있다.\n",
        "\n",
        "Sequential API\n",
        "- Sequential API는 가장 간단한 형태의 모델을 생성하는 방법 중 하나로, 레이어를 순차적으로 쌓아 올리는 방식으로 모델을 정의. 각 레이어는 바로 이전 레이어의 출력을 입력으로 받아 처리.\n",
        "- Sequential 모델은 단순한 순차적 구조를 가진 신경망에 적합하며, 복잡한 모델 구조(예: 다중 입력/출력, 모델 내 레이어 간 병렬 연결 등)를 표현하는 데는 한계가 있다.\n",
        "\n",
        "함수형(Functional) API\n",
        "- 함수형 API는 더 유연한 모델 설계를 가능하게 하는 API로, 복잡한 모델 아키텍처를 구성할 수 있다.\n",
        "- 함수형 API를 사용하면 다중 입력 및 출력, 공유 레이어(동일한 레이어를 여러 번 사용), 레이어 간 복잡한 연결 구조 등을 정의할 수 있다. 이는 각 레이어의 입출력을 명시적으로 정의함으로써 달성된다. 함수형 API는 고급 사용자에게 더 많은 유연성과 제어력을 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0_QzbvQLhmK"
      },
      "source": [
        "[ 활성화 함수 ]\n",
        "- ReLU(Rectified Linear Unit): 'f(x) = max(0, x)'로 정의되어 널리 사용되는 활성화 함수입니다. 계산 효율성이 높으면서도 비선형성이 도입되어 훈련 중에 모델이 빠르게 수렴될 수 있다.\n",
        "- 시그모이드: 이 활성화 함수는 0과 1 사이의 값을 출력하므로 이진 분류 문제에 적합.\n",
        "- 소프트맥스: 각 클래스에 대한 확률을 얻기 위해 분류기의 출력 레이어에서 자주 사용되는 소프트맥스 함수는 여러 클래스에 대한 확률 분포를 출력.\n",
        "- Tanh(하이퍼볼릭 탄젠트): 시그모이드와 비슷하지만 -1과 1 사이의 값을 출력."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPNZb65hKf2Z"
      },
      "source": [
        "Q. Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network구성하기\n",
        "- 입력 레이어는 28*28의 입력특성을 가진 입력 레이어\n",
        "- 입력 레이어는 32개의 뉴런을 가지고 있고 ReLU 활성화 함수를 사용\n",
        "- 은닉 레이어는 64개의 뉴런을 가지고 있고 ReLU 활성화 함수를 사용\n",
        "- 출력 레이어는 10개의 뉴런을 가지고 있고 소프트맥스 활성화 함수를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8K4r44nAeaP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28*28,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYYLsmSPdCe"
      },
      "source": [
        "- 신경망 및 딥러닝의 맥락에서 옵티마이저는 손실을 줄이기 위해 가중치, 학습률 등 신경망의 속성을 변경하는 데 사용되는 알고리즘 또는 방법.\n",
        "- 옵티마이저는 학습 프로세스의 속도와 품질에 직접적인 영향을 미치므로 학습 프로세스에 매우 중요.\n",
        "- 최적화의 목표는 비용 함수(또는 손실 함수)를 최소화하는 모델에 대한 최상의 매개변수(가중치)를 찾는 것이다. 이 프로세스는 모델이 특정 작업에 대한 정확성과 성능을 향상시키는 데 필수적이다.\n",
        "\n",
        "[ 옵티마이저 유형 ]\n",
        "\n",
        "가중치를 조정하기 위한 자체 메커니즘과 전략을 가진 여러 가지 최적화 프로그램이 있습니다. 가장 일반적으로 사용되는 최적화 도구는 다음과 같다.\n",
        "\n",
        "- 확률적 경사하강법(SGD): 이것은 가장 간단한 최적화 프로그램 중 하나. 각 훈련 예제를 개별적으로 사용하여 모델의 가중치를 업데이트. 여기에는 각 단계에서 훈련 데이터의 하위 집합을 사용하여 더 효율적으로 만드는 미니 배치 경사하강법(Mini-Batch Gradient Descent)과 같은 변형이 있다.\n",
        "- 모멘텀: 이 최적화 프로그램은 관련 방향을 따라 탐색하여 SGD를 가속화하고 현재 업데이트 벡터에 과거 단계의 업데이트 벡터의 일부를 추가하여 높은 곡률 방향의 진동을 완화.\n",
        "- Adagrad: 학습 속도를 매개변수에 맞게 조정하여 자주 발생하는 기능과 관련된 매개변수에 대해 더 작은 업데이트를 수행하고, 자주 발생하지 않는 기능과 관련된 매개변수에 대해 더 큰 업데이트를 수행.\n",
        "- RMSprop: 이 최적화 프로그램은 가중치에 대한 학습률을 해당 가중치에 대한 최근 기울기 크기의 이동 평균으로 나눈다. 이는 Geoff Hinton이 강의에서 제안한 미공개 적응형 학습률 방법.\n",
        "- Adam(Adaptive Moment Estimation): AdaGrad 및 RMSprop 알고리즘의 최상의 속성을 결합하여 노이즈 문제에 대한 희소 기울기를 처리할 수 있는 최적화 알고리즘을 제공.\n",
        "\n",
        "[ 옵티마이저 작동 방식 ]\n",
        "\n",
        "- 최적화 프로그램은 모델 매개변수에 대한 손실 함수의 기울기를 사용하여 조정. 이 기울기는 손실을 최소화하기 위해 가중치를 조정해야 하는 방향을 나타낸다. 가중치를 반복적으로 업데이트함으로써 최적화 프로그램은 모델의 최고 성능에 해당하는 손실 함수의 가장 낮은 지점에 도달하려고 한다.\n",
        "- 최적화 프로그램의 선택은 신경망의 성능에 큰 영향을 미칠 수 있으며, 최선의 선택은 특정 문제, 데이터의 성격, 신경망 아키텍처에 따라 달라질 수 있다. Adam은 다양한 문제에 대한 적응성과 성능으로 인해 기본적으로 좋은 선택이 되는 경우가 많지만, 특정 작업과 데이터 세트에는 다른 최적화 프로그램이 도움이 될 수 있다. 주어진 시나리오에 가장 효과적인 최적화 프로그램을 식별하려면 일반적으로 실험과 교차 검증이 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnXUTVwrPiTA"
      },
      "source": [
        "[ 손실 함수라고도 알려진 비용 함수 ]\n",
        "- 모델의 예측 출력과 실제 목표 값 간의 차이를 측정하는 수학적 함수입니다. 이는 모델의 오류를 정량화하여 훈련 중 최적화 프로세스에 대한 가이드 역할을 한다.\n",
        "- 신경망 훈련의 목표는 이 비용 함수를 최소화하는 것이다. 이는 모델이 예측하는 것과 실제로 관찰되는 것 사이의 오류를 효과적으로 줄이는 것을 의미.\n",
        "- 고급 신경망 API인 Keras는 다양한 유형의 문제에 대해 다양한 비용 함수를 내장하고 있으며 필요한 경우 사용자 정의 손실 함수를 생성할 수도 있다. 비용 함수의 선택은 분류, 회귀 등과 같이 해결되는 문제의 구체적인 성격에 따라 달라다.\n",
        "\n",
        "[ Keras의 일반적인 비용 함수 ]\n",
        "- 평균 제곱 오차(MSE): 회귀 문제에 사용됩니다. 예측값과 실제값 사이의 오차 제곱의 평균을 계산. keras.losses.MeanSquaredError()\n",
        "- 이진 교차엔트로피: 이진 분류 문제에 사용됩니다. 두 확률 분포, 즉 실제 레이블 분포와 예측 확률 사이의 거리를 측정. keras.losses.BinaryCrossentropy()\n",
        "- 범주형 교차엔트로피: 레이블이 원-핫 인코딩되는 다중 클래스 분류 문제에 사용. 이진 교차엔트로피와 유사하지만 여러 클래스에 적용. keras.losses.keras.losses.CategoricalCrossentropy()\n",
        "- 희소 범주형 교차엔트로피: 범주형 교차엔트로피와 유사하지만 레이블이 정수인 경우에 사용됩니다. 클래스가 많은 경우에는 메모리 효율성이 더 높다. keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zLQN0JjStQu"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dWQ4-sgVHxd"
      },
      "source": [
        "[ 배치 크기 ]\n",
        "- 배치 크기는 기계 학습에 사용되는 용어로, 모델 학습 프로세스의 한 번의 반복에서 활용되는 학습 예제의 수를 나타낸다.\n",
        "- 신경망 훈련의 맥락에서 데이터 세트는 일반적으로 여러 배치로 나뉘며 모델의 가중치는 각 배치를 처리한 후 업데이트된다.\n",
        "- 배치 크기의 선택은 수렴 속도와 훈련 프로세스의 안정성을 포함한 훈련 역학에 큰 영향을 미칠 수 있다.\n",
        "\n",
        "- 작은 배치 크기: 각 업데이트 내에서 더 많은 노이즈로 더 빠른 업데이트가 가능. 이는 때때로 모델이 로컬 최소값을 벗어나는 데 도움이 될 수 있지만 훈련 과정을 더욱 불안정하게 만들 수도 있다.\n",
        "- 대형 배치 크기: 기울기에 대한 더 정확한 추정치를 제공하며 업데이트 시 노이즈가 적다. 이는 더 안정적이지만 잠재적으로 더 느린 훈련으로 이어질 수 있습니다. 또한 대규모 배치에는 더 많은 메모리가 필요하므로 일부 하드웨어에서는 제한 요소가 될 수 있다.\n",
        "\n",
        "[ 에포크 ]\n",
        "- 에포크는 전체 훈련 데이터세트를 한 번 통과하는 것을 나타낸다. 한 epoch 동안 신경망은 모든 훈련 예제를 한 번 처리한다. 따라서 훈련의 에포크 수에 따라 학습 알고리즘이 전체 훈련 데이터 세트에서 작동하는 횟수가 결정된다.\n",
        "- 너무 적은 에포크를 실행하면 모델이 훈련 데이터에서 충분히 학습하지 못하는 과소적합이 발생할 수 있다.\n",
        "- 너무 많은 에포크를 실행하면 과적합이 발생할 수 있다. 즉, 모델이 노이즈를 포함하여 훈련 데이터에서 패턴을 너무 잘 학습하여 보이지 않는 데이터에 대한 성능이 저하될 수 있다.\n",
        "\n",
        "[ 배치 크기와 에포크 간의 관계 ]\n",
        "- 배치 크기 영향: 배치 크기는 가중치를 업데이트하기 전에 확인하는 예시 수를 결정. 배치가 작을수록 한번에 더 많은 업데이트가 이루어지며 잠재적으로 학습 속도가 빨라지지만 너무 작으면 불안정해질 수 있다. 배치가 클수록 더 안정적인 기울기 추정이 제공되지만 학습 속도가 느려지고 더 많은 메모리가 필요할 수 있다.\n",
        "- 에포크 영향: 에포크 수에 따라 학습 알고리즘이 전체 데이터 세트를 순환하는 횟수가 결정. Epoch가 많을수록 모델이 가중치를 학습하고 조정할 수 있는 기회가 더 많아지지만 숫자가 너무 높으면 과적합이 발생할 위험이 있다.\n",
        "- 요약하자면, 배치 크기와 에포크 수는 신중하게 균형을 맞춰야 하는 신경망 훈련의 두 가지 기본 하이퍼파라미터이다. 이러한 매개변수의 최적 설정은 특정 데이터세트와 문제는 물론 사용 가능한 계산 리소스에 따라 달라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vM3pJ4VLej"
      },
      "source": [
        "Q. 모델을 간단한 데이터셋이 적용하여 학습하기\n",
        "- MNIST 데이터셋을 사용\n",
        "- 배치 사이즈는 32, 에포크 수는 10으로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ruR-bsGVKxg",
        "outputId": "26055069-5758-419c-8fa4-22bf97391fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.5742\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1746\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1334\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1068\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0917\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0781\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0708\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0650\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0577\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0513\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0eb93298d0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 784)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHkM_XmaXIrt"
      },
      "source": [
        "Q. 모델 평가하기\n",
        "- 테스트 데이터셋을 사용하여 모델을 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GiqbJspXM7g",
        "outputId": "7e413ba2-711e-4309-9f3e-1114c1764e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1369\n",
            "Test accuracy: 0.9674000144004822\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "V6EHqiczXu1w",
        "outputId": "ff7b8eaf-e913-4bc5-b484-352db9b1d9eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m25,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,648</span> (326.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,648\u001b[0m (326.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,882</span> (108.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,882\u001b[0m (108.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,766</span> (217.84 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m55,766\u001b[0m (217.84 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCStfdXsbyRA"
      },
      "source": [
        "Q. MNIST 데이터셋에 대하여 Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network) 구성하세요.\n",
        "- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화.Flatten(input_shape=(28, 28))\n",
        "\n",
        "- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n",
        "\n",
        "- 컴파일:\n",
        "  - optimizer='adam',\n",
        "  - loss='sparse_categorical_crossentropy',\n",
        "  - metrics=['accuracy']\n",
        "\n",
        "- epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwSDzo57eypU",
        "outputId": "b7157c6a-f8e4-4e8d-d143-75d152ac8cb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<Flatten name=flatten_2, built=False>,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "\n",
        "Input(shape=(28*28,)),\n",
        "Flatten(input_shape=(28, 28)),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBS0kBkOb1-5",
        "outputId": "5fd8a556-c431-431d-a765-3d8d8de4eb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.4264\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1196\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0765\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0550\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9875 - loss: 0.0412\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0846\n",
            "Test accuracy: 0.9765999913215637\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "LAJ-RJbXhKJn",
        "outputId": "756e48a6-d767-448e-ebd0-07da8cb4b3f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFSYIyXqkeyB"
      },
      "source": [
        "각 레이어의 파라미터 개수 계산\n",
        "- Input 레이어: 파라미터가 없습니다.\n",
        "\n",
        "- Flatten 레이어: 파라미터가 없습니다. 입력 형태를 (28, 28)에서 (784,)로 변환합니다.\n",
        "\n",
        "- 첫 번째 Dense 레이어: 입력 뉴런 784개, 출력 뉴런 128개\n",
        "  - 파라미터 개수 = 784 * 128 + 128 = 100,480\n",
        "  - 각 입력 뉴런이 각 출력 뉴런과 연결되므로, 총 가중치 파라미터 수는 784 x 128이고 각 출력 뉴런마다 하나의 바이어스 파라미터가 추가되어 128개 추가\n",
        "- 두 번째 Dense 레이어: 입력 뉴런 128개, 출력 뉴런 10개\n",
        "  - 파라미터 개수 = 128 * 10 + 10 = 1290"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXm4Fsc9lbDs"
      },
      "source": [
        "[ 완전신경망(완전연결신경망, Fully Connected Neural Network)에서 각 층의 파라미터 수 계산 ]\n",
        "\n",
        "- 각 연결에 하나의 가중치가 있으므로, 특정 층의 가중치 수는 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱한 값과 같다.\n",
        "- 각 뉴런에는 하나의 편향이 있으므로, 특정 층의 편향 수는 해당 층의 뉴런 수와 같다.\n",
        "- 특정 층의 총 파라미터 수는 가중치 수와 편향 수의 합이다.\n",
        "\n",
        "가중치의 의미\n",
        "- 이전 층의 뉴런 수: 각 뉴런은 이전 층의 모든 뉴런으로부터 입력 신호를 받는다. 이전 층에 더 많은 뉴런이 있을수록, 현재 층의 한 뉴런이 처리해야 할 입력 신호의 수가 더 많아진다.\n",
        "- 해당 층의 뉴런 수: 해당 층에 더 많은 뉴런이 있다는 것은, 이전 층의 각 뉴런으로부터 오는 신호를 받아들이는 더 많은 처리 단위가 있다는 것을 의미.\n",
        "- 가중치의 역할: 각 가중치는 입력 신호의 중요도를 조정. 즉, 특정 입력이 해당 뉴런의 활성화에 얼마나 영향을 미치는지 결정하는 역할을 한다. 가중치는 학습 과정에서 조정되며, 신경망이 훈련 데이터로부터 패턴을 학습하는 방식을 결정.\n",
        "\n",
        "가중치 수 계산\n",
        "- 신경망에서 정보가 전달되는 방식과 학습이 어떻게 이루어지는지를 나타낸다. 각 가중치는 이전 층의 특정 뉴런과 현재 층의 특정 뉴런 사이의 연결 강도를 나타내며 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱하는 것은 모든 가능한 연결을 고려하여 이들 간의 관계를 정량화하는 방법이다.\n",
        "- 계산 과정을 통해 각 연결마다 하나의 고유한 가중치가 할당"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjZ13G5-lmyT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dormQSUlpQm"
      },
      "source": [
        "[ 픽셀(pixel) ]\n",
        "- 디지털 이미지를 구성하는 기본 단위. 단어 \"픽셀\"은 \"Picture Element\"의 줄임말로, 이미지를 구성하는 가장 작은 단일 색상의 점을 의미. 각 픽셀은 특정 색상과 밝기 값을 가지며, 이러한 픽셀들이 모여 전체 이미지를 형성\n",
        "- 색상과 밝기: 컬러 이미지에서 각 픽셀은 일반적으로 빨강(Red), 초록(Green), 파랑(Blue)의 세 가지 색상 채널 값을 가지며, 이를 RGB 값이라고 한다. 각 채널의 값은 보통 0에서 255 사이의 정수로 표현되며, 이 값들의 조합을 통해 다양한 색상을 나타낸다. 그레이스케일 이미지에서는 단일 채널만 사용하여 밝기를 표현하며, 0은 검은색, 255는 흰색을 의미하고, 그 사이의 값은 다양한 회색 음영을 나타낸다.\n",
        "- 해상도: 이미지의 해상도는 이미지의 세부 사항과 선명도를 결정하는 중요한 요소입니다. 해상도가 높은 이미지는 더 많은 픽셀을 가지며, 따라서 더 세밀한 디테일을 표현할 수 있다. 예를 들어, 1920x1080 해상도의 이미지는 가로 1920픽셀, 세로 1080픽셀로 구성되어 있다.\n",
        "- 디지털 표현: 디지털 이미지 처리, 컴퓨터 그래픽, 디지털 카메라 촬영과 같은 분야에서 픽셀은 기본적인 작업 단위로 사용되며 이미지의 품질, 색상 처리, 이미지 분석 등은 모두 픽셀 데이터를 기반으로 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZTJuV9oqXei"
      },
      "source": [
        "[ Mnist데이터셋 ]\n",
        "\n",
        "- 입력 크기가 (28, 28)인 것은 각 이미지가 28픽셀의 너비와 28픽셀의 높이를 가진 2차원 그레이스케일 이미지라는 것을 의미\n",
        "- 각 이미지는 단일 색상 채널(그레이스케일)을 가지며, 픽셀 값은 일반적으로 0(완전 검정)에서 255(완전 백색) 사이의 값을 가진다. 따라서, 각 이미지는 28x28=784개의 픽셀로 구성되며, 각 픽셀은 해당 위치에서의 밝기 또는 색상 강도를 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPYzt7cZqMQn",
        "outputId": "90e3eab2-8a52-442b-9636-ebec58f19476"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "FmKAJhfCrEXK",
        "outputId": "afb4e481-3cc3-40c0-9feb-a295b8aba3e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-3be16c81-07b2-4fd9-bba6-6fff885671cb\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-3be16c81-07b2-4fd9-bba6-6fff885671cb button').onclick = (e) => {\n",
              "        document.querySelector('#id-3be16c81-07b2-4fd9-bba6-6fff885671cb').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-3be16c81-07b2-4fd9-bba6-6fff885671cb button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ],
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "QtrW9WqnrJG2",
        "outputId": "137c19b5-d9b7-4be4-b882-cecaecd8132f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = train_images[0]  # Reshape back to 2D format if necessary\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image_data, cmap='gray') # Display the image\n",
        "plt.axis('off')   # Turn off the axis numbers/labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_-hecadrmZO",
        "outputId": "b94a834a-3cc0-4b96-c3c1-d15dc4dd1d4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images[1].reshape(784,).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP-kpFa4r_ch"
      },
      "source": [
        "MNIST 데이터세트의 모양을 (60000, 28, 28)에서 (60000, 784)로 변경하는 이유\n",
        "- 기계 학습의 일반적인 전처리 단계이며, 특히 완전히 연결된(밀집된) 신경망의 맥락에서 필요하며 이 프로세스를 이미지 \"평탄화\"라고 한다.\n",
        "\n",
        "[ 주요 이유 ]\n",
        "- 신경망의 입력 형식: 신경망의 완전 연결된 레이어에서는 입력이 1D 벡터일 것으로 예상. 각 입력 뉴런은 다음 레이어의 모든 출력 뉴런에 연결.\n",
        "- 이미지의 원래 2D 구조(28x28픽셀)는 공간 정보를 2차원으로 표현하기 때문에 이러한 기대에 맞지 않다. 이미지를 1D 벡터(이 경우 784개 요소)로 평면화하면 각 픽셀이 네트워크에 제공될 수 있는 개별 특징이 된다.\n",
        "- 단순화: 평면화는 정보 손실 없이 데이터 구조를 단순화. 각 픽셀 값은 여전히 ​​전체 입력에 기여하지만 네트워크 계층에서 수행되는 수학적 연산(예: 내적)과 호환되는 형식.\n",
        "- 네트워크 아키텍처와의 호환성: 대부분의 기본 신경망 아키텍처, 특히 입문 목적이나 간단한 작업에 사용되는 아키텍처는 다차원 데이터가 아닌 기능 벡터로 작동하도록 설계. CNN(컨벌루션 신경망)은 다차원 데이터를 직접 처리할 수 있지만(픽셀 간 공간 계층 보존) 완전 연결된 네트워크는 본질적으로 이러한 데이터를 처리하지 않는다.\n",
        "- 효율성: 평면화된 이미지로 작업하는 것은 때때로 특정 작업에 대해 계산적으로 더 효율적일 수 있다. 특히 신경망에서 데이터 배치를 처리하기 위해 행렬 곱셈을 사용할 때 더욱 그렇다.\n",
        "- 그러나 병합하면 픽셀 간의 공간적 관계가 삭제된다는 점에 유의하는 것이 중요. 이는 이미지 인식이나 객체 위치 파악과 같이 픽셀의 공간적 배열이 중요한 작업에는 적합하지 않다. 이러한 작업의 경우 CNN(컨벌루션 신경망)이 공간 계층을 유지하면서 2D 이미지를 처리할 수 있어 네트워크가 픽셀 배열을 기반으로 더 복잡한 패턴을 학습할 수 있으므로 더 적합하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ndZjWU0tTwM"
      },
      "source": [
        "[ 레이블이 원-핫 인코딩되지 않은 이유 ]\n",
        "\n",
        "모델의 손실 함수(loss function)로 'sparse_categorical_crossentropy'가 사용되기 때문. TensorFlow와 Keras에서 두 가지 유형의 크로스엔트로피 손실 함수를 제공하며, 각각은 다음과 같은 경우에 사용된다:\n",
        "\n",
        "- 'sparse_categorical_crossentropy': 이 손실 함수는 레이블이 정수 형태로 제공될 때 사용. 즉, 각 샘플에 대해 단일 정수로 클래스 레이블이 지정되며, 이 경우 원-핫 인코딩을 할 필요가 없다. 이 함수는 내부적으로 정수 레이블을 적절한 원-핫 인코딩 형태로 변환하여 처리.\n",
        "\n",
        "- 'categorical_crossentropy': 이 손실 함수는 레이블이 원-핫 인코딩된 형태로 제공될 때 사용. 각 샘플의 레이블이 벡터이며, 벡터의 각 원소는 해당 클래스의 소속 여부를 나타낸다(클래스에 속하면 1, 아니면 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjaE4bbAtlpl"
      },
      "source": [
        "### Convolutional Neural Network (CNN)\n",
        "CNN은 컨벌루션 레이어와 풀링 레이어를 사용하여 이미지의 공간 계층 구조를 캡처할 수 있기 때문에 이미지 처리 작업에 특히 적합\n",
        "\n",
        "[ CNN 아키텍처 ]\n",
        "- 컨볼루션 레이어(Conv2D): 이 레이어는 컨볼루션 작업을 수행하여 이미지에서 공간 특징을 캡처.\n",
        "- 풀링 레이어 (MaxPooling2D): 이 레이어는 다음 컨벌루션 레이어에 대한 입력 볼륨의 공간 크기(높이 및 너비)를 줄인다. 이는 계산 부하와 메모리 사용량을 줄이고 표현의 추상화된 형식을 제공하여 과적합을 줄이는 데 사용.\n",
        "- 밀집 레이어(완전 연결 레이어): 여러 컨볼루션 및 풀링 레이어 이후 신경망의 상위 수준 추론은 컨볼루션 레이어에서 추출하고 평면화한 특징을 기반으로 분류를 수행하는 Dense 레이어를 통해 수행.\n",
        "- 모델은 컨벌루션 레이어와 밀집 레이어에 'relu' 활성화를 사용(10자리 클래스에 대한 확률을 출력하기 위해 'softmax'를 사용하는 출력 레이어 제외). 다중 클래스 분류 작업에 적합한 adam 최적화 프로그램과 categorical_crossentropy 손실 함수로 컴파일.\n",
        "\n",
        "이 CNN 아키텍처를 사용하면 MNIST와 같은 이미지 분류 작업에서 높은 정확도를 달성하는 데 중요한 이미지 내 공간 관계를 활용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjKP0xx6sCSo",
        "outputId": "6271f17b-5b17-4699-9706-55786d3436af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9100 - loss: 0.3032\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0375\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0266\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0171\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0151\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0420\n",
            "Test accuracy:, 0.989799976348877\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# 원 핫 인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# 32개의 필터, 각 필터의 크기는 3x3, 28x28 픽셀의 흑백 이미지 (채널 수 1)\n",
        "model.add(layers.InputLayer(shape=(28, 28, 1)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 3))) # 입력 이미지의 크기를 줄이는데 사용되며 주요 특징을 유지하면서 계산량을 줄인다\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f'Test accuracy:, {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "sCw6iJJQzgI5",
        "outputId": "ded59e45-a310-4a0f-afef-78f8e51f42f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3840</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">245,824</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3840\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m245,824\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906,656</span> (3.46 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906,656\u001b[0m (3.46 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">302,218</span> (1.15 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m302,218\u001b[0m (1.15 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">604,438</span> (2.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m604,438\u001b[0m (2.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI6Y4tSjYLcB"
      },
      "source": [
        "함수형 API\n",
        "\n",
        "Keras 내장 데이터셋인 Fashion MNIST를 사용하여 분류 모델을 학습하고 평가하세요.\n",
        "- Fashion MNIST는 기존의 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(예: 티셔츠, 바지, 신발 등)의 이미지로 구성\n",
        "- 입력층, 두 개의 은닉층, 그리고 Softmax 활성화 함수를 사용하는 출력층으로 구성\n",
        "- 모델은 Adam 최적화 알고리즘과 categorical_crossentropy 손실 함수를 사용하여 컴파일\n",
        "- 학습 과정에서 정확도를 평가 지표로 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2xRwHVYe46",
        "outputId": "ab07d77f-442c-4cf6-fcbb-c13a8bfeb25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7599 - loss: 0.6689 - val_accuracy: 0.8463 - val_loss: 0.4267\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8646 - loss: 0.3680 - val_accuracy: 0.8587 - val_loss: 0.3800\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8796 - loss: 0.3232 - val_accuracy: 0.8796 - val_loss: 0.3287\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.8912 - loss: 0.2935 - val_accuracy: 0.8816 - val_loss: 0.3302\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8945 - loss: 0.2803 - val_accuracy: 0.8842 - val_loss: 0.3132\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9018 - loss: 0.2661 - val_accuracy: 0.8810 - val_loss: 0.3206\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9080 - loss: 0.2463 - val_accuracy: 0.8745 - val_loss: 0.3438\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9104 - loss: 0.2400 - val_accuracy: 0.8926 - val_loss: 0.3071\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9139 - loss: 0.2275 - val_accuracy: 0.8918 - val_loss: 0.3116\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9152 - loss: 0.2199 - val_accuracy: 0.8927 - val_loss: 0.3101\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3340\n",
            "Test accuracy: 0.8863999843597412\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지를 0 ~ 1 범위로 스케일링\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# 레이블을 원-핫 인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# 입력 데이터의 차원\n",
        "input_shape = (784,)\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# 완전연결 층 추가\n",
        "hidden1 = Dense(512, activation='relu', name='hidden_layer1')(input_layer)\n",
        "hidden2 = Dense(256, activation='relu', name='hidden_layer2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjtIBEILbqR9"
      },
      "source": [
        "Q. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아키텍처의 신경망을 구성하여 학습 및 평가를 수행하세요.\n",
        "- 입력층 : shape=(28, 28)\n",
        "- 은닉층 1 : 128, relu\n",
        "- 은닉층 2 : 64, relu\n",
        "- 출력층 : 10, softmax\n",
        "- 비용함수 : sparse_categorical_crossentro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhJk_uWMbr6H",
        "outputId": "71271039-9851-4da6-c2d8-c751ceb6409c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8063 - loss: 0.6838 - val_accuracy: 0.9505 - val_loss: 0.1787\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.1636 - val_accuracy: 0.9617 - val_loss: 0.1292\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1067 - val_accuracy: 0.9666 - val_loss: 0.1121\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0757 - val_accuracy: 0.9662 - val_loss: 0.1071\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0586 - val_accuracy: 0.9727 - val_loss: 0.0926\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0455 - val_accuracy: 0.9707 - val_loss: 0.0996\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0383 - val_accuracy: 0.9733 - val_loss: 0.0940\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0286 - val_accuracy: 0.9716 - val_loss: 0.0975\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0255 - val_accuracy: 0.9768 - val_loss: 0.0871\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0201 - val_accuracy: 0.9750 - val_loss: 0.0899\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0955\n",
            "Test accuracy: 0.9771000146865845\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "input_layer = Input(shape=(28, 28), name='input_layer')\n",
        "x = Flatten()(input_layer)\n",
        "\n",
        "\n",
        "hidden1 = Dense(128, activation='relu', name='hidden_layer1')(x)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer2')(hidden1)\n",
        "\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 생성\n",
        "model_functional = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model_functional.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model_functional.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_functional.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w41KfryYg6OZ",
        "outputId": "aa40f8e4-de53-43cf-967e-7f08c080ac23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Predicted class: 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 새로운 이미지 데이터 예시 (여기서는 실제 새로운 이미지 대신 테스트 이미지 중 하나를 사용)\n",
        "# 실제 사용 시에는 새로운 이미지 데이터를 여기에 로드하고 전처리해야 합니다\n",
        "# 예를 들어, 새로운 이미지가 하나만 있는 경우, 이미지를 (28, 28) 형태로 리사이징하고 정규화 해야 합니다\n",
        "new_image = test_images[0] # 실제로는 새로운 이미지 데이터를 사용해야 합니다\n",
        "# [배치 크기, 이미지 높이, 이미지 너비, 채널 수]\n",
        "new_image = np.expand_dims(new_image, axis=0) # 모델 입력을 위해 배치 차원 추가 (28, 28)에서 (1, 28, 28)\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predictions = model_functional.predict(new_image)\n",
        "\n",
        "# 예측 결과 출력\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print('Predicted class:', predicted_class[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18AGVWXfig2N",
        "outputId": "3297e43e-feb5-4d81-b536-adc8ab5334e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 10)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(predictions.shape)\n",
        "predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pnA8Ftxh-5d",
        "outputId": "0c465fb1-5466-4a57-a179-815cc147b1ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "OrLz1tHjlE_7",
        "outputId": "f6c96b48-8fde-4db7-ce4c-ba766ef70a3e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = test_images[0]  # Reshape back to 2D format if necessary\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image_data, cmap='gray') # Display the image\n",
        "plt.axis('off')   # Turn off the axis numbers/labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qdbAPJ6mecs"
      },
      "source": [
        "[ 선형 회귀 활성화 함수 ]\n",
        "- 선형 회귀 모델의 출력 레이어는 보통 단일 뉴런으로 구성되며 활성화 함수가 없는  형태를 취하며 이는 모델이 어떠한 범위의 값을 직접 출력할 수 있게 하기 위함이다.\n",
        "- 활성화 함수는 신경망에서 비선형성을 도입하기 위해 사용. 비선형 활성화 함수(예: ReLU, 시그모이드, 탄젠트 등)를 사용하면 신경망은 복잡한 패턴과 비선형 관계를 학습할 수 있다. 그러나 선형 회귀에서는 모델 출력이 입력 변수의 선형 조합으로 표현되어야 하므로, 비선형 활성화 함수를 사용할 필요가 없다.\n",
        "- 따라서 선형 회귀 모델의 경우, 출력 계층에 \"linear\" 활성화 함수를 명시적으로 설정하거나 (이는 입력에 대한 아무런 변환도 적용하지 않는 것과 동일), 아예 활성화 함수를 지정하지 않는 것이 일반적. Keras에서 Dense 계층을 추가할 때 activation 매개변수를 설정하지 않으면 기본적으로 \"linear\" 활성화 함수가 사용된다. 즉, 출력 뉴런의 값은 입력에 대한 선형 변환 결과이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unY9EOSbmnzK",
        "outputId": "07847b5b-b6f2-4797-ddc5-925bd90a2af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 8283.5205\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2048.7200\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1127.6416\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 987.0509\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 961.1287\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 952.0827\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 945.5492\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 939.4184\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 933.3803\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 927.3890\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 921.4377\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 915.5251\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 909.6508\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 903.8146\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 898.0160\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 892.2552\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 886.5316\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 880.8451\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 875.1952\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 869.5821\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 864.0052\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 858.4644\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 852.9597\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 847.4905\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 842.0567\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 836.6581\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 831.2945\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 825.9655\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 820.6711\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 815.4112\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 810.1850\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 804.9929\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 799.8342\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 794.7089\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 789.6169\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 784.5580\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 779.5317\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 774.5379\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 769.5765\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 764.6472\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 759.7499\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 754.8842\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 750.0500\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 745.2473\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 740.4755\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 735.7346\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 731.0244\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 726.3447\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 721.6954\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 717.0761\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 712.4868\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 707.9272\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 703.3972\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 698.8964\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 694.4247\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 689.9822\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 685.5681\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 681.1828\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 676.8259\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 672.4971\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 668.1965\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 663.9237\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 659.6783\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 655.4608\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 651.2704\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 647.1072\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 642.9708\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 638.8613\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 634.7784\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 630.7219\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 626.6917\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 622.6876\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 618.7094\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 614.7570\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 610.8302\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 606.9288\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 603.0526\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 599.2017\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 595.3756\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 591.5742\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 587.7975\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 584.0452\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 580.3173\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 576.6135\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 572.9336\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 569.2777\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 565.6454\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 562.0365\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 558.4511\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 554.8888\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 551.3497\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 547.8335\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 544.3400\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 540.8690\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 537.4207\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 533.9946\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 530.5908\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 527.2089\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 523.8488\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 520.5106\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7db0677d4190>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# 텐서플로/케라스에서 실행하는 선형 회귀\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 텐서플로의 케라스 API에서 필요한 함수들을 불러옵니다\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "x = np.array([2, 4, 6, 8]) # 공부 시간\n",
        "y = np.array([81, 93, 91, 97]) # 성적\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 출력값 , 입력 변수, 분석방법에 맞게끔 모델을 설정\n",
        "model.add(Input(shape=(1,)))\n",
        "model.add(Dense(1))\n",
        "# model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "\n",
        "# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "# 오차를 최소화하는 과정을 2000번 반복\n",
        "model.fit(x, y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x, y)\n",
        "plt.plot(x, model.predict(x),'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "2IAzfBYsp4p_",
        "outputId": "c4d96638-4b54-47ac-d1aa-b59f1cb76557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "hour = 7\n",
        "# 리스트를 numpy 배열로 변환하고 reshape하여 예측에 사용\n",
        "prediction = model.predict(np.array([hour]).reshape(-1, 1))\n",
        "\n",
        "print('%.f시간을 공부할 경우의 예상점수는 %.02f 점 입니다' % (hour, prediction[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "yny7KN9bvfoB",
        "outputId": "7b481a16-bbb9-4dcc-a9d2-7385090ad2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int64)\n  • training=False\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-61c7faf38a07>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 리스트를 numpy 배열로 변환하고 reshape하여 예측에 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%.f시간을 공부할 경우의 예상점수는 %.02f 점 입니다'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int64)\n  • training=False\n  • mask=None"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}